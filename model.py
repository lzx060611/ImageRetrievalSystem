# model.py
import os
import torch
import open_clip  # ä½ ç”¨çš„æ¨¡å‹åŠ è½½åº“
from PIL import Image
import pydicom  # å¤„ç†DICOMåŒ»å­¦å›¾åƒ
from tqdm import tqdm  # æ‰¹é‡æå–æ—¶æ˜¾ç¤ºè¿›åº¦æ¡
import warnings
warnings.filterwarnings("ignore")  # å¿½ç•¥æ— å…³è­¦å‘Š
from NIH import NIH_dataset 
from torch.utils.data import DataLoader

#ä¸€ã€åŠ è½½æ¨¡å‹
# 1. æ¨¡å‹é…ç½®ï¼ˆæ”¹ç®—æ³•æ—¶ä¼˜å…ˆæ”¹è¿™éƒ¨åˆ†ï¼‰
MODEL_NAME = 'hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224'
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# äºŒ. æ‰¹é‡æå–é…ç½®ï¼ˆæ ¹æ®ä½ çš„æ•°æ®é›†è°ƒæ•´è·¯å¾„ï¼‰
IMG_ROOT = "./images_001/images"  # ä½ çš„å›¾ç‰‡æ ¹ç›®å½•
IMG_LIST = "images_001\\train_val_list.txt"  # ä½ çš„å›¾ç‰‡åˆ—è¡¨æ–‡ä»¶
BATCH_SIZE = 50                       # ä½ çš„æ‰¹æ¬¡å¤§å°
SAVE_DIR = "nih_features_db"          # ç‰¹å¾ä¿å­˜æ–‡ä»¶å¤¹
SAVE_PATH = os.path.join(SAVE_DIR, "nih_biomedclip_features.pt")  # ç‰¹å¾ä¿å­˜è·¯å¾„
#ä¸‰ã€åŠ è½½æ¨¡å‹
# ===================== æ¨¡å‹æ ¸å¿ƒé€»è¾‘ï¼ˆå°è£…æˆå¯å¤ç”¨å‡½æ•°ï¼‰=====================
def load_model():
    """
    å°è£…æ¨¡å‹åŠ è½½é€»è¾‘ï¼šæ”¹ç®—æ³•æ—¶åªéœ€ä¿®æ”¹è¿™ä¸ªå‡½æ•°ï¼
    è¿”å›ï¼šmodel, preprocess_valï¼ˆæ¨ç†é¢„å¤„ç†ï¼‰, tokenizer
    """
    # è§£å†³å›½å†…HFåŠ è½½æ…¢çš„é—®é¢˜
    os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
    
    # åŠ è½½æ¨¡å‹+é¢„å¤„ç†å·¥å…·ï¼ˆæ”¹ç®—æ³•æ—¶æ›¿æ¢è¿™é‡Œï¼Œæ¯”å¦‚æ¢æˆResNet/è‡ªå®šä¹‰æ¨¡å‹ï¼‰
    model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms(MODEL_NAME)
    tokenizer = open_clip.get_tokenizer(MODEL_NAME)
    
    # æ¨¡å‹é…ç½®ï¼ˆè¯„ä¼°æ¨¡å¼+è®¾å¤‡åˆ†é…ï¼‰
    model.eval()
    model = model.to(DEVICE)
    
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ | è®¾å¤‡ï¼š{DEVICE} | æ¨¡å‹ï¼š{MODEL_NAME}")
    return model, preprocess_val, tokenizer

# å…¨å±€åŠ è½½æ¨¡å‹ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼Œé¿å…é‡å¤åŠ è½½æµªè´¹å†…å­˜ï¼‰
model, preprocess_val, tokenizer = load_model()


# ----------------------
# å››. å°è£…ç‰¹å¾æå–å‡½æ•°ï¼ˆä¾›åç«¯è°ƒç”¨ï¼‰
# è¾“å…¥ï¼šPIL.Imageå¯¹è±¡
# è¾“å‡ºï¼šå½’ä¸€åŒ–åçš„ç‰¹å¾å‘é‡ï¼ˆnumpyæ ¼å¼ï¼Œshape=(256,)ï¼‰
# ----------------------
def extract_image_feature(image):
    """
    åŠŸèƒ½ï¼šå•å¼ å›¾ç‰‡ç‰¹å¾æå–ï¼ˆå’Œä½ æ‰¹é‡æå–çš„é€»è¾‘ä¸€è‡´ï¼‰
    å‚æ•°ï¼šimage - PIL.Imageå¯¹è±¡ï¼ˆRGBæ ¼å¼ï¼‰
    è¿”å›ï¼šnumpyæ•°ç»„ï¼ˆ256ç»´ç‰¹å¾å‘é‡ï¼‰
    """
    try:
        # é¢„å¤„ç†ï¼ˆå’Œä½ çš„collate_fné‡Œçš„é¢„å¤„ç†é€»è¾‘ä¸€è‡´ï¼‰
        processed_img = preprocess_val(image).unsqueeze(0).to(DEVICE)
        
        # ç‰¹å¾æå–ï¼ˆå’Œä½ çš„æ‰¹é‡æå–é€»è¾‘ä¸€è‡´ï¼‰
        with torch.no_grad():
            img_feature = model.encode_image(processed_img)
        
        # L2å½’ä¸€åŒ–ï¼ˆå’Œä½ çš„æ‰¹é‡å¤„ç†é€»è¾‘å®Œå…¨ä¸€è‡´ï¼‰
        img_feature = torch.nn.functional.normalize(img_feature, p=2, dim=1)
        
        # è½¬ä¸ºnumpyå¹¶å»é™¤batchç»´åº¦ï¼ˆ(1, 512) â†’ (512,)ï¼‰
        return img_feature.cpu().numpy()[0]
    
    except Exception as e:
        raise ValueError(f"å•å¼ å›¾ç‰‡ç‰¹å¾æå–å¤±è´¥ï¼š{str(e)}")
    

# ===================== æ‰¹é‡ç‰¹å¾æå–ï¼ˆå®Œå…¨å¤ç”¨ä½ çš„DataLoaderé€»è¾‘ï¼‰=====================
def custom_collate_fn(batch):
    """
    ä½ çš„è‡ªå®šä¹‰collate_fn
    è¾“å…¥ï¼šbatchæ˜¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯æ•°æ®é›†è¿”å›çš„ (image, img_path)
    è¾“å‡ºï¼šæ•´ç†åçš„ (å›¾åƒæ‰¹æ¬¡å¼ é‡, è·¯å¾„åˆ—è¡¨)
    """
    images, paths = zip(*batch)  # åˆ†ç¦»å›¾åƒå’Œè·¯å¾„ï¼ˆimagesæ˜¯PILå›¾åƒå…ƒç»„ï¼Œpathsæ˜¯è·¯å¾„å…ƒç»„ï¼‰
    # 1. ç”¨preprocess_valé€ä¸ªå¤„ç†PILå›¾åƒï¼Œè½¬ä¸ºå¼ é‡ï¼ˆå’Œä½ çš„é€»è¾‘ä¸€è‡´ï¼‰
    processed_images = [preprocess_val(img) for img in images]
    # 2. å°†å¤šä¸ªå¼ é‡å †å æˆæ‰¹æ¬¡ï¼ˆshape: [batch_size, 3, 224, 224]ï¼‰
    image_batch = torch.stack(processed_images)
    # 3. è·¯å¾„ç›´æ¥ä¿æŒåˆ—è¡¨å½¢å¼
    path_batch = list(paths)
    return image_batch, path_batch

def batch_extract_features():
    """
    æ‰¹é‡æå–ç‰¹å¾ï¼ˆå®Œå…¨å¤ç”¨ä½ çš„DataLoaderé€»è¾‘ï¼‰
    æ— éœ€ä¼ å‚ï¼Œç›´æ¥ç”¨å…¨å±€é…ç½®é¡¹ï¼ˆå’Œä½ çš„è·¯å¾„/å‚æ•°å¯¹é½ï¼‰
    """
    # 1. åŠ è½½ä½ çš„NIHæ•°æ®é›†ï¼ˆå’Œä½ çš„ä»£ç ä¸€è‡´ï¼‰
    print(f"ğŸ“‚ åŠ è½½NIHæ•°æ®é›† | å›¾ç‰‡æ ¹è·¯å¾„ï¼š{IMG_ROOT} | åˆ—è¡¨æ–‡ä»¶ï¼š{IMG_LIST}")
    NiH_data = NIH_dataset(IMG_ROOT, IMG_LIST)
    
    # 2. åˆ›å»ºDataLoaderï¼ˆå¤ç”¨ä½ çš„collate_fnå’Œbatch_sizeï¼‰
    NIH_loader = DataLoader(
        NiH_data, 
        batch_size=BATCH_SIZE, 
        collate_fn=custom_collate_fn  # ç”¨ä½ çš„è‡ªå®šä¹‰collate_fn
    )
    print(f"âœ… DataLoaderåˆ›å»ºå®Œæˆ | æ‰¹æ¬¡å¤§å°ï¼š{BATCH_SIZE} | æ€»æ‰¹æ¬¡ï¼š{len(NIH_loader)}")

    # 3. æ‰¹é‡æå–ç‰¹å¾ï¼ˆå’Œä½ çš„é€»è¾‘å®Œå…¨ä¸€è‡´ï¼‰
    all_features = []
    all_paths = []

    print("\nğŸš€ å¼€å§‹æ‰¹é‡æå–ç‰¹å¾...")
    with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦ï¼ŒèŠ‚çœå†…å­˜
        # åŠ è¿›åº¦æ¡ï¼Œæ–¹ä¾¿çœ‹æå–è¿›åº¦
        for batch_images, batch_paths in tqdm(NIH_loader, desc="æå–è¿›åº¦"):
            # å›¾åƒç§»åˆ°è®¾å¤‡ï¼ˆå’Œä½ çš„ä»£ç ä¸€è‡´ï¼‰
            batch_images = batch_images.to(DEVICE)
            
            # æå–ç‰¹å¾ï¼ˆå’Œä½ çš„ä»£ç ä¸€è‡´ï¼‰
            batch_features = model.encode_image(batch_images)
            batch_features = torch.nn.functional.normalize(batch_features, p=2, dim=1)
            
            # ä¿å­˜ç‰¹å¾å’Œè·¯å¾„ï¼ˆå’Œä½ çš„ä»£ç ä¸€è‡´ï¼‰
            all_features.append(batch_features.cpu())
            all_paths.extend(batch_paths)

    # 4. åˆå¹¶æ‰€æœ‰ç‰¹å¾ï¼ˆå’Œä½ çš„ä»£ç ä¸€è‡´ï¼‰
    all_features = torch.cat(all_features, dim=0)
    print(f"\nğŸ“Š æå–å®Œæˆ | ç‰¹å¾å½¢çŠ¶ï¼š{all_features.shape} | æœ‰æ•ˆå›¾ç‰‡æ•°ï¼š{len(all_paths)}")

    # 5. ä¿å­˜ç‰¹å¾å’Œè·¯å¾„ï¼ˆå’Œä½ çš„æ ¼å¼å®Œå…¨ä¸€è‡´ï¼‰
    os.makedirs(SAVE_DIR, exist_ok=True)  # åˆ›å»ºä¿å­˜æ–‡ä»¶å¤¹
    features_db = {
        "features": all_features,  # ç‰¹å¾å‘é‡ (N, 512)ï¼Œå’Œä½ çš„ç»´åº¦ä¸€è‡´
        "image_paths": all_paths   # å¯¹åº”å›¾åƒè·¯å¾„åˆ—è¡¨
    }
    torch.save(features_db, SAVE_PATH)

    print(f"âœ… ç‰¹å¾æ•°æ®åº“å·²ä¿å­˜åˆ°ï¼š{SAVE_PATH}")
    print(f"ç‰¹å¾å½¢çŠ¶ï¼š{all_features.shape}ï¼ŒåŒ…å« {len(all_paths)} å¼ å›¾åƒ")

# ===================== ä¸€é”®è¿è¡Œæ‰¹é‡æå–ï¼ˆç›´æ¥æ‰§è¡Œmodel.pyå³å¯ï¼‰=====================
if __name__ == "__main__":
    # è¿è¡Œæ‰¹é‡æå–ï¼ˆå’Œä½ çš„é€»è¾‘å®Œå…¨ä¸€è‡´ï¼‰
    batch_extract_features()
